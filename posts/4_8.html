<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>15464 - Blog</title>                           <!-- Give Title -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="style.css">  <!-- Insert StyleSheet -->
    <link rel="icon" href="cool-icon.png">                    <!-- Insert Icon -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
</head>
<body BGCOLOR="e7fef9">

    <h1>15-464 Blog</h1>
    
    <p>
    <h4><b>Student:  </b>Oscar Dadfar</h4>
    <p>
    <p>
    <a href="../index.html">Home</a>
    <p>
    
    <p>
    <hr size=2 width="100%" align=center>
    
    <div style='width: 95%; margin-left: 2.5%;'>
        <p>4/8/2020</p>

         <p>Animation faces can be a tedious process, and I've seen a lot of NLP-based algorithms for lip-synching and expression generation based on the tone and syllabary. Some of the papers we saw today included deep-learning approaches, but it was interesting to see the last paper with applications in stop-motion. I'm curious to see the effects this would have on large-scale stop-motion films like Kubo or any up-coming stop-motion films. Having a computer-assisted 3D part generation surely assists the stop-motion animation pipeline.</p>
    </div>
    
    <hr size=2 width="100%" align=center>
    
</body>
</html>
